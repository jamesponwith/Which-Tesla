{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesponwith/anaconda/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "train_datagen=ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "valid_datagen=ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen=ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "jf_datagen=ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Augmented images to use for training and testing purposes\n",
    "# train_generator=train_datagen.flow_from_directory('Data',target_size=(128,128),\n",
    "#                                                   save_to_dir='output_photos/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i=0\n",
    "# for batch in train_generator:\n",
    "#     i +=1\n",
    "#     if(i>=10):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i=0\n",
    "# for batch in jf_datagen.flow_from_directory('Data',target_size=(128,128),save_to_dir='output_photos/'):\n",
    "#     i +=1\n",
    "#     if(i>=10):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jamesponwith/Desktop/Qualcomm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path, dirs, files = next(os.walk(\"CombinedData/\"))\n",
    "file_count = len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CombinedData/\n"
     ]
    }
   ],
   "source": [
    "print(path) # CombinedData/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Valid', 'Test', 'ModelS', 'Train', 'ModelX']\n"
     ]
    }
   ],
   "source": [
    "print(dirs) # ['Valid', 'Test', 'ModelS', 'Train', 'ModelX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly splitting the photos from the ModelS/ and ModelX/ folders into Train/ (70%), Valid/ (15%), and Test/ (15%)  \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA HAS ALREADY BEEN PARSED \n",
    "# # # Parse Data for Model S\n",
    "# i = 0\n",
    "# train_image_list = []\n",
    "# original_len = len(os.listdir(path+dirs[2]))\n",
    "# while i < (.7*original_len):\n",
    "#     train_image_list.append(random.choice(os.listdir(\"CombinedData/ModelS/\")))\n",
    "#     os.rename(('CombinedData/ModelS/'+train_image_list[i]), ('CombinedData/Train/ModelS/'+train_image_list[i]))\n",
    "#     i = i + 1\n",
    "# i = 0\n",
    "# while i < (.15*original_len):\n",
    "#     train_image_list.append(random.choice(os.listdir(\"CombinedData/ModelS/\")))\n",
    "#     os.rename(('CombinedData/ModelS/'+train_image_list[i]), ('CombinedData/Valid/ModelS/'+train_image_list[i]))\n",
    "#     i = i + 1\n",
    "# i = 0\n",
    "# while i < (.15*original_len):\n",
    "#     train_image_list.append(random.choice(os.listdir(\"CombinedData/ModelS/\")))\n",
    "#     os.rename(('CombinedData/ModelS/'+train_image_list[i]), ('CombinedData/Test/ModelS/'+train_image_list[i]))\n",
    "#     i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA HAS ALREADY BEEN PARSED \n",
    "# # Parse Data for Model X\n",
    "# i = 0\n",
    "# train_image_list = []\n",
    "# original_len = len(os.listdir(path+dirs[4]))\n",
    "# while i < (.7*original_len):\n",
    "#     train_image_list.append(random.choice(os.listdir(\"CombinedData/ModelX/\")))\n",
    "#     os.rename(('CombinedData/ModelX/'+train_image_list[i]), ('CombinedData/Train/ModelX/'+train_image_list[i]))\n",
    "#     # Move the actual file then duplicates should happen?\n",
    "#     i = i + 1\n",
    "# i = 0\n",
    "# while i < (.15*original_len):\n",
    "#     train_image_list.append(random.choice(os.listdir(\"CombinedData/ModelX/\")))\n",
    "#     os.rename(('CombinedData/ModelX/'+train_image_list[i]), ('CombinedData/Valid/ModelX/'+train_image_list[i]))\n",
    "#     i = i + 1\n",
    "# i = 0\n",
    "# while i < (.15*original_len):    \n",
    "#     train_image_list.append(random.choice(os.listdir(\"CombinedData/ModelX/\")))\n",
    "#     os.rename(('CombinedData/ModelX/'+train_image_list[i]), ('CombinedData/Test/ModelX/'+train_image_list[i]))\n",
    "#     i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 260 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=r\"CombinedData/Train/\",\n",
    "    target_size=(128, 128),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=12,\n",
    "    class_mode=\"categorical\", \n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory=r\"CombinedData/Valid/\",\n",
    "    target_size=(128, 128),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=12,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=r\"CombinedData/Test/\",\n",
    "    target_size=(128, 128),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Creating Model\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input, Dense\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(256, (3, 3), input_shape=(128,128,3))) # changed from 3 to 2 when attempting Greyscale\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(256, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "# model.add(Dense(64))\n",
    "\n",
    "# model.add(Dense(2)) # 2\n",
    "# # model.add(Dense(1))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "cnn3 = Sequential()\n",
    "cnn3.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128,128,3)))\n",
    "cnn3.add(MaxPooling2D((2, 2)))\n",
    "cnn3.add(Dropout(0.25))\n",
    "\n",
    "cnn3.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn3.add(Dropout(0.25))\n",
    "\n",
    "cnn3.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn3.add(Dropout(0.4))\n",
    "\n",
    "cnn3.add(Flatten())\n",
    "\n",
    "cnn3.add(Dense(128, activation='relu'))\n",
    "cnn3.add(Dropout(0.3))\n",
    "cnn3.add(Dense(2, activation='softmax'))\n",
    "\n",
    "cnn3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21/21 [==============================] - 20s 938ms/step - loss: 2.5233 - acc: 0.5060 - val_loss: 0.6789 - val_acc: 0.5909\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 15s 711ms/step - loss: 0.6948 - acc: 0.5477 - val_loss: 0.6797 - val_acc: 0.7045\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 19s 925ms/step - loss: 0.6765 - acc: 0.5595 - val_loss: 0.6883 - val_acc: 0.5833\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 18s 863ms/step - loss: 0.6666 - acc: 0.5698 - val_loss: 0.6747 - val_acc: 0.5455\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 24s 1s/step - loss: 0.6613 - acc: 0.5853 - val_loss: 0.6689 - val_acc: 0.6818\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 16s 771ms/step - loss: 0.6737 - acc: 0.6051 - val_loss: 0.6321 - val_acc: 0.6364\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 17s 829ms/step - loss: 0.6340 - acc: 0.6369 - val_loss: 0.5172 - val_acc: 0.8409\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 21s 997ms/step - loss: 0.5042 - acc: 0.7521 - val_loss: 0.3728 - val_acc: 0.8542\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 35s 2s/step - loss: 0.5471 - acc: 0.7422 - val_loss: 0.3858 - val_acc: 0.8182\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 33s 2s/step - loss: 0.4179 - acc: 0.7977 - val_loss: 0.4000 - val_acc: 0.8182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12bdf4160>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "# model.fit_generator(generator=train_generator,\n",
    "cnn3.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3958605094389482, 0.8863636472008445]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "# model.evaluate_generator(generator=valid_generator,\n",
    "cnn3.evaluate_generator(generator=valid_generator,\n",
    "steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 2s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict output\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "# pred=model.predict_generator(test_generator,\n",
    "pred=cnn3.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results_guess_the_Tesla.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
